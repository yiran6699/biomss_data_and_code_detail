from xgboost import XGBRegressor as XGBR
from sklearn.ensemble import RandomForestRegressor as RFR
from sklearn.linear_model import LinearRegression as LinearR
from sklearn.datasets import load_boston
from sklearn.model_selection import KFold, cross_val_score as CVS, train_test_split as TTS
from sklearn.metrics import mean_squared_error as MSE
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from time import time
import datetime
from sklearn.preprocessing import StandardScaler 
import xgboost as xgb
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import GridSearchCV
from sklearn.feature_selection import mutual_info_regression as MIR

def mean_absolute_percentage_error(y_true, y_pred): 
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

data = pd.read_csv("TOTALBio-0.csv")
x = data.iloc[:,1:]
y = data.iloc[:,0]

cv_params = {'n_estimators': np.arange(100,10000,100)}
other_params = {'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'seed': 0,
                'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}
model = xgb.XGBRegressor(**other_params)
GS = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_absolute_error', cv=5, verbose=1, n_jobs=-1)
GS.fit(x, y)
print('参数的最佳取值：{0}'.format(GS.best_params_))
print('最佳模型得分:{0}'.format(GS.best_score_))

cv_params = {'n_estimators': np.arange(10,200,10)}
other_params = {'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'seed': 0,
                'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}
model = xgb.XGBRegressor(**other_params)
GS = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_absolute_error', cv=5, verbose=1, n_jobs=-1)
GS.fit(x, y)
print('参数的最佳取值：{0}'.format(GS.best_params_))
print('最佳模型得分:{0}'.format(GS.best_score_))

cv_params = {'n_estimators': np.arange(70,120,1)}
other_params = {'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'seed': 0,
                'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}
model = xgb.XGBRegressor(**other_params)
GS = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_absolute_error', cv=5, verbose=1, n_jobs=-1)
GS.fit(x, y)
print('参数的最佳取值：{0}'.format(GS.best_params_))
print('最佳模型得分:{0}'.format(GS.best_score_))

cv_params = {'max_depth': np.arange(1,10,1), 'min_child_weight': np.arange(1,10,1)}
other_params = {'learning_rate': 0.1, 'n_estimators': 93, 'max_depth': 5, 'min_child_weight': 1, 'seed': 0,
                'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}
model = xgb.XGBRegressor(**other_params)
GS = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_absolute_error', cv=5, verbose=1, n_jobs=-1)
GS.fit(x, y)
print('参数的最佳取值：{0}'.format(GS.best_params_))
print('最佳模型得分:{0}'.format(GS.best_score_))

cv_params = {'gamma': np.arange(0,1,0.01)}
other_params = {'learning_rate': 0.1, 'n_estimators': 93, 'max_depth': 4, 'min_child_weight': 1, 'seed': 0,
                'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}
model = xgb.XGBRegressor(**other_params)
GS = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_absolute_error', cv=5, verbose=1, n_jobs=-1)
GS.fit(x, y)
print('参数的最佳取值：{0}'.format(GS.best_params_))
print('最佳模型得分:{0}'.format(GS.best_score_))

cv_params = {'subsample': np.arange(0,1,0.1), 'colsample_bytree': np.arange(0,1,0.1)}
other_params = {'learning_rate': 0.1, 'n_estimators': 93, 'max_depth': 4, 'min_child_weight': 1, 'seed': 0,
                'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}
model = xgb.XGBRegressor(**other_params)
GS = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_absolute_error', cv=5, verbose=1, n_jobs=-1)
GS.fit(x, y)
print('参数的最佳取值：{0}'.format(GS.best_params_))
print('最佳模型得分:{0}'.format(GS.best_score_))

cv_params = {'reg_alpha': np.arange(0,10,1), 'reg_lambda': np.arange(0,10,1)}
other_params = {'learning_rate': 0.1, 'n_estimators': 93, 'max_depth': 4, 'min_child_weight': 1, 'seed': 0,
                'subsample': 0.5, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}
model = xgb.XGBRegressor(**other_params)
GS = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_absolute_error', cv=5, verbose=1, n_jobs=-1)
GS.fit(x, y)
print('参数的最佳取值：{0}'.format(GS.best_params_))
print('最佳模型得分:{0}'.format(GS.best_score_))

cv_params = {'learning_rate': np.arange(0,1,0.01)}
other_params = {'learning_rate': 0.1, 'n_estimators': 93, 'max_depth': 4, 'min_child_weight': 1, 'seed': 0,
                'subsample': 0.5, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}
model = xgb.XGBRegressor(**other_params)
GS = GridSearchCV(estimator=model, param_grid=cv_params, scoring='neg_mean_absolute_error', cv=5, verbose=1, n_jobs=-1)
GS.fit(x, y)
print('参数的最佳取值：{0}'.format(GS.best_params_))
print('最佳模型得分:{0}'.format(GS.best_score_))

model = xgb.XGBRegressor(learning_rate=0.1, n_estimators=93, max_depth=4, min_child_weight=1, seed=0,
                         subsample=0.5, colsample_bytree=0.8, gamma=0, reg_alpha=0, reg_lambda=1)

score_mae = CVS(model, x, y, cv = 5, scoring = "neg_mean_absolute_error")
score_mse = CVS(model, x, y, cv = 5, scoring = "neg_mean_squared_error")
model.fit(x,y)
pred = model.predict(x)

print("五次的mae：", -score_mae)
print("平均的mae:",-score_mae.mean())
print("五次的mae：", -score_mse)
print("平均的mse:",-score_mse.mean())
print("平均的rmse:", np.sqrt(-score_mse.mean()))
mape = mean_absolute_percentage_error(y, pred)
print("平均的mape:", mape)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
r2 = r2_score(y, pred)
print(r2)



